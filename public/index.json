[{"content":"\rI specialize in developing tools and implementing advanced Machine Learning solutions to tackle challenges within Data Science and Data-Driven Analytics.\nLearn More\r","date":null,"permalink":"/","section":"","summary":"I specialize in developing tools and implementing advanced Machine Learning solutions to tackle challenges within Data Science and Data-Driven Analytics.","title":""},{"content":"Random things I wrote.\n","date":null,"permalink":"/blog/","section":"Blog","summary":"Random things I wrote.","title":"Blog"},{"content":"","date":null,"permalink":"/tags/data-science/","section":"Tags","summary":"","title":"Data Science"},{"content":"Hello internet, welcome to my personal website üê£! First time doing this, let\u0026rsquo;s see how it goes!\nDisplay some Math: #Einstein\u0026rsquo;s famous Mass-energy equivalence formula üåå:\n$$ E = mc^2 $$\nFrom wiki: The formula defines the energy E of a particle in its rest frame as the product of mass m with the speed of light squared (c¬≤).\nThe üîî Curve: With the probability density function:\n$$ f(x | Œº, œÉ^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp \\left( -\\frac{(x - Œº)^2}{2 \\sigma^2} \\right) $$\nWhere Œº is the mean or expectation of the distribution and œÉ is the standard deviation. i.e. variance of œÉ¬≤. It is also known as the Gaussian Distribution or more commonly known as the Normal Distribution. An example graph of the function:\nIllustration of the Probability Density Function of a Standard Normal Distribution\rEmbedding code block #This is the R code used to generate the above graph.\n#Clear console and environment rm(list = ls()) cat(\u0026#34;\\014\u0026#34;) #attach required library library(ggplot2) library(dplyr) #set mu and sigma parameters for the Normal Curve mu\u0026lt;-0 sigma\u0026lt;-1 #generate data x\u0026lt;-seq(-4*sigma,4*sigma,0.0001)-0.5 y\u0026lt;-dnorm(x,mu,sigma) #density function data\u0026lt;-cbind(x=x,y=y) %\u0026gt;% data.frame() xlab\u0026lt;-c(expression(-3*sigma) ,expression(-2*sigma) ,expression(-sigma) ,expression(mu) ,expression(sigma) ,expression(2*sigma) ,expression(3*sigma) ) p_lab\u0026lt;-pnorm(seq(-3*sigma,3*sigma,sigma),mu,sigma) #Plot: ggplot(data,aes(x,y))+ #Plot area settings: theme_classic()+ theme(plot.title=element_text(size=40,face=\u0026#34;bold\u0026#34;,hjust=0.5) ,panel.grid.major.x=element_line(size = (0.2)) ,axis.text.x=element_blank())+ ggtitle(\u0026#34;Standard Normal Distribution\u0026#34;)+ xlab(\u0026#34;x\u0026#34;)+ #text for the sigma labels annotate(\u0026#34;text\u0026#34;, x = seq(-3*sigma,3*sigma,sigma), y = rep(-0.005,7), label = xlab, family = \u0026#34;\u0026#34;, fontface = 3, size=8) + #text for the density values at each n*sigma area annotate(\u0026#34;text\u0026#34;, x = c(seq(-3*sigma,3*sigma,sigma)-0.5*sigma,0.5*sigma+3*sigma), y = round(c(p_lab[1],diff(p_lab),p_lab[1]),1)^2+0.05, label = paste0(round(c(p_lab[1],diff(p_lab),p_lab[1])*100,1),\u0026#34;%\u0026#34;), family = \u0026#34;\u0026#34;, fontface = 8, size=8) + #display parameter values annotate(\u0026#34;text\u0026#34;, x = rep(2.2*sigma,2), y = c(0.16,0.14), label = c(expression(paste(mu,\u0026#34;=\u0026#34;)), expression(paste(sigma,\u0026#34;=\u0026#34;))), family = \u0026#34;\u0026#34;, fontface = 3, size=8) + annotate(\u0026#34;text\u0026#34;, x = rep(2.4*sigma,2), y = c(0.164,0.143), label = c(mu,sigma), family = \u0026#34;\u0026#34;, fontface = 3, size=7) + scale_x_continuous(breaks=seq(-3*sigma,3*sigma,sigma),limits=c(-3.5*sigma,3.5*sigma))+ ylab(\u0026#34;Probability Density\u0026#34;)+ scale_y_continuous(labels=scales::percent_format(accuracy=1))+ geom_line() Some Linear Algebra: #To find a plane of best-fit. Given a data vector with n samples and p parameters:\n$$ \\begin{Bmatrix} y_i, x_{i1},\\cdot \\cdot \\cdot ,x_{ip} \\end{Bmatrix}^{n}_{i=1} $$\nWhere the dependent variable y and the p-size vector of regressors x are assumed to be a linear relationship. Where the error variable Œµ was modeled such that it is the minimum and ideally it experiences an unobserved random variable. i.e. \u0026ldquo;noise\u0026rdquo;.\nThen ideally we want to find Œ≤ where the model has the form:\n$$ y_i = \\beta_0 + \\beta_1 x_1 + \\cdot \\cdot \\cdot + \\beta_p x_{ip} + \\varepsilon_i = x^T \\beta + \\varepsilon $$\nOr simply\n$$ y = X \\beta + \\varepsilon $$\nWhere\n$$ y = \\begin{Bmatrix} y_1, \\cdot \\cdot \\cdot y_n \\end{Bmatrix}^T $$\n$$ X = \\begin{pmatrix} x^T_1 \\\\\\ \\cdot \\\\\\ \\cdot \\\\\\ \\cdot \\\\\\ x^T_n \\end{pmatrix} = \\begin{pmatrix} 1 \u0026amp; x_{11} \u0026amp; \\cdot\\cdot\\cdot \u0026amp; x_{1p} \\\\\\ \u0026amp; \u0026amp; \\cdot \u0026amp; \\\\\\ \u0026amp; \u0026amp; \\cdot \u0026amp; \\\\\\ \u0026amp; \u0026amp; \\cdot \u0026amp; \\\\\\ 1 \u0026amp; x_{n1} \u0026amp; \\cdot\\cdot\\cdot \u0026amp; x_{np} \\end{pmatrix} $$\nand\n$$ \\beta = \\begin{pmatrix} \\beta_0 \\\\\\ \\beta_1 \\\\\\ \\cdot \\\\\\ \\cdot \\\\\\ \\cdot \\\\\\ \\beta_p \\end{pmatrix} , \\varepsilon = \\begin{pmatrix} \\varepsilon_1 \\\\\\ \\cdot \\\\\\ \\cdot \\\\\\ \\varepsilon_n \\end{pmatrix} $$\nHence for a line, you are solving for the equation with one parameter $$y = \\beta_0 + \\beta_1 x$$ and for a plane there will be two parameters. $$y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2$$\nLeast-squares estimation: #Since y and x are assumed to be a linear relationship and we would like to find the \u0026ldquo;best\u0026rdquo; Œ≤ which solve the system of equations and to minimize Œµ. Hence let: $$ \\varepsilon = L(X,y,\\hat{\\beta})=\\left | X\\hat{\\beta}-y \\right |^2 = (X\\hat{\\beta} - y)^T(X\\hat{\\beta}-y) \\ $$ $$ = y^Ty - y^TX\\hat{\\beta} - \\hat{\\beta}^TX^Ty + \\hat{\\beta}^TX^TX\\hat{\\beta} $$ Where L is called the Loss function, essentially the error term is modeled with the input X, y, Œ≤. Since X, y is the original data we want to \u0026ldquo;fit\u0026rdquo;, therefore we can find the \u0026ldquo;best\u0026rdquo; Œ≤ at which L(X, y, Œ≤) is minimized.\nHence the first derivative of L(X, y, Œ≤):\n$$ \\frac{\\partial L(X,y,\\hat{\\beta})}{\\partial \\hat{\\beta}} = -2X^Ty+2X^TX\\hat{\\beta} $$\nSince X, y is fixed and known and we only interested in the \u0026ldquo;best\u0026rdquo; Œ≤ therefore:\n$$ \\hat{\\beta} = (X^TX)^{-1}X^Ty $$\nThis is the case for the Simple Linear Regression.\nThis concludes the Hello World! üåé Thank you for reading!\n","date":"24 Jun, 2024","permalink":"/blog/hello_world/","section":"Blog","summary":"Hello internet, welcome to my personal website üê£!","title":"Hello World! üåé"},{"content":"","date":null,"permalink":"/tags/linear-algebra/","section":"Tags","summary":"","title":"Linear Algebra"},{"content":"","date":null,"permalink":"/tags/machine-learning/","section":"Tags","summary":"","title":"Machine Learning"},{"content":"Interesting projects I\u0026rsquo;ve done in the past.\n","date":null,"permalink":"/projects/","section":"Projects","summary":"Interesting projects I\u0026rsquo;ve done in the past.","title":"Projects"},{"content":"","date":null,"permalink":"/tags/python/","section":"Tags","summary":"","title":"Python"},{"content":"","date":null,"permalink":"/tags/r/","section":"Tags","summary":"","title":"R"},{"content":"I am working on putting my projects here. Stay tuned and I hope you will visit back later! Meanwhile, take a look at my R√©sum√© or check out my first blog here.\nHere is me working on it\u0026hellip;.\nLorem ipsum #Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\nLorem ipsum #Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n","date":"24 Jun, 2024","permalink":"/projects/stay_tuned/","section":"Projects","summary":"More projects is being curated here . . .","title":"Stay tuned"},{"content":"","date":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":null,"permalink":"/tags/classification/","section":"Tags","summary":"","title":"Classification"},{"content":"","date":null,"permalink":"/tags/feature-engineering/","section":"Tags","summary":"","title":"Feature Engineering"},{"content":"","date":null,"permalink":"/tags/image-processing/","section":"Tags","summary":"","title":"Image Processing"},{"content":"\rPhoto of a Photo ¬© Steven Lio\rIntroduction #The goal of this project was to develope a classification machine learning model as a proof-of-concept capable of reliably detecting wheather an image is an original photograph or a scanned reproduction of another picture for Trusting Pixel Inc. (Vancouver, Canada). This project served as my Capstone project during my Master of Data Science program at the University of British Columbia where I collaborated with three other students.\nDisclaimer: Due to NDA, I am not able to disclose details of the model but I will document the process of discovery and challenges we faced during the project.\nBackground #Image authenticity recognition is crucial for upholding trust and credibility in digital content, preventing misinformation, and protecting intellectual property. Advancements in deep learning models like DALL-E which is capable of generating realistic images which prompt more reseaches focus into image authenitication. But I believe most of these researches maybe hidden from the public because revealing the principle behind any security system will immediately compromise its effectiveness.\nFor most people, likely the \u0026ldquo;photo of a photo\u0026rdquo; problem isn\u0026rsquo;t significant. However, for companies in the fashion and entertainment industries, they rely heavily on reviewing unaltered professional headshots or body shots of the models, actors, and actresses they are considering for hire.\nThis project piqued my interest because I have been experimenting with different computer vision techniques even before getting my master\u0026rsquo;s degree and have always wanted to gain more experiences in developing Neural Networks.\nData Preprocessing #Trusting Pixel Inc. provided the project with a collection of geninue digital images as well as their recaptured version on the printed photo. The first challenge we faced was the lack of linkage between the geninue images and their recaptured counterparts. This is important for developing a model that extract clues and evidence unique to recaptured images of photos and not memorizing the subjects in the training images.\nI developed a process in Python for automatically pairing the geninue image with its recaptured counterpart and return the pair in the same orientation.\nIn order to find the similar pair of images, I\u0026rsquo;ve first calculated a similarity score (0 to 1) between the image and all the other images in the set. Then the image in the set with the highest score will get paired up. Then repeat until all images has found at least a pair. I\u0026rsquo;ve calculated a similarity score for each possible pair of images using the SIFT1 algorithm.\nIt worked amazingly well even when I am trying to pair a geninue images with a picture of its printed photo.\nClick here to see a implementation of SIFT Similarity calculation in Python:\rimport cv2 import matplotlib.pyplot as plt def sift_similarity(img1, img2): \u0026#34;\u0026#34;\u0026#34; Calculate similarity scores based on SIFT descriptors Args: img1 (numpy.ndarray): Input image 1 img2 (numpy.ndarray): Input image 2 Returns: float: similarity scores between image 1 and image 2 \u0026#34;\u0026#34;\u0026#34; sift = cv2.SIFT_create() kp_1, desc_1 = sift.detectAndCompute(img1, None) kp_2, desc_2 = sift.detectAndCompute(img2, None) index_params = dict(algorithm=0, trees=5) search_params = dict() flann = cv2.FlannBasedMatcher(index_params, search_params) matches = flann.knnMatch(desc_1, desc_2, k=2) good_points = [] ratio = 0.6 for m, n in matches: if m.distance \u0026lt; ratio*n.distance: good_points.append(m) #calculate similarity score: number_keypoints = 0 if len(kp_1) \u0026lt;= len(kp_2): number_keypoints = len(kp_1) else: number_keypoints = len(kp_2) try: match_rate = len(good_points) / number_keypoints except: match_rate = 0 return match_rate # Test on images img1 = cv2.imread(\u0026#34;img1.jpeg\u0026#34;) img2 = cv2.imread(\u0026#34;img2.jpeg\u0026#34;) img3 = cv2.imread(\u0026#34;img3.jpeg\u0026#34;) # Display images fig, axes = plt.subplots(1, 3, figsize=(15,5)) axes[0].imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)) axes[0].set_title(\u0026#39;Image 1\u0026#39;) axes[0].axis(\u0026#39;off\u0026#39;) axes[1].imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)) axes[1].set_title(\u0026#39;Image 2\u0026#39;) axes[1].axis(\u0026#39;off\u0026#39;) axes[2].imshow(cv2.cvtColor(img3, cv2.COLOR_BGR2RGB)) axes[2].set_title(\u0026#39;Image 3\u0026#39;) axes[2].axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() # Print scores to console print(\u0026#34;SIFT Similarity between \u0026#39;Image 1\u0026#39; and \u0026#39;Image 1\u0026#39; is {0:.2f}.\u0026#34;.format(sift_similarity(img1, img1))) print(\u0026#34;SIFT Similarity between \u0026#39;Image 1\u0026#39; and \u0026#39;Image 2\u0026#39; is {0:.2f}.\u0026#34;.format(sift_similarity(img1, img2))) print(\u0026#34;SIFT Similarity between \u0026#39;Image 2\u0026#39; and \u0026#39;Image 3\u0026#39; is {0:.2f}.\u0026#34;.format(sift_similarity(img2, img3))) Image 1\rImage 2\rImage 3\rThe output from the Python script:\nSIFT Similarity between \u0026#39;Image 1\u0026#39; and \u0026#39;Image 1\u0026#39; is 1.00. SIFT Similarity between \u0026#39;Image 1\u0026#39; and \u0026#39;Image 2\u0026#39; is 0.67. SIFT Similarity between \u0026#39;Image 2\u0026#39; and \u0026#39;Image 3\u0026#39; is 0.26. After having pairing the images, they were moved to a new folder and renamed to keep track of their pairing, making them ready for the next step.\nModeling #Although Convolution Neural Networks (CNNs) are popular for solving computer vision tasks with images data, it wasn\u0026rsquo;t entirely feasible at the time due to our small dataset and limited computing power, making training a large Neural Network unrealistic.\nThat led us to using traditional classification models. However, these models require a feature matrix as input, and feeding the full-sized images would result in an enormous matrix. After analyzing the geninue images and their recaptured counterparts, we noticed that recaptured images exhibit distinct characteristics. Resizing the images for modeling would have caused us to lose these critical details, which is also why we didn\u0026rsquo;t start with CNNs. The unique features of recaptured images arise from the printing process, where some original image details are lost and new features, like the texture of the print, are added.\nTherefore, we began research image processing techniques to extract these features precisely. We compared the resulting feature value distributions produced by each techniques and to decide the techniques to apply and which features to create.\nWe trained multiple clasifical models with the feature matrix, performing hyperparameter tuning and evaluatng the goodness of the fit to arrive at the final model that best distinguished between geninue image vs. recaptured images for the images we had.\nAlthough we attempted to use CNNs, the results were not significantly better in classifying the testing images. However this does not rule out the possibility that CNNs could eventually prove to be the best overall approach.\nCaveats #The project aims to showcase the potential of using the described method to detect photo of photos as a proof-of-concept. To develop a final model that can handle real-world scenarios, much more image data is needed for training. Additionally, the selected features may only be effective for the specific types of prints from the recaptured images in the training data.\nWe did found some features that showned potential for different types of recaptured images upon testing on various sources. However, I won\u0026rsquo;t be disclosing them.\nFinal Product #Besides the proof-of-concept machine learning model, we\u0026rsquo;ve also created a demo application using Dash in Python. It allows a human judge to process new images within the application and assess the results before making a final decision.\nThe application handles uploaded images, apply the necessary feature extraction, inputs them into the best model for prediction, and displays a confidence score in the app.\nWhat I\u0026rsquo;ve learned #Through this project, I gained extensive knowledge about various image processing techniques, and leaned how combining these techniques can help train a functional image classification machine learning model with limited data.\nReferences #1\r\u003c?xml version=\"1.0\" encoding=\"iso-8859-1\"?\u003e\r\u003c!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"\u003e\rScale-invariant feature transform (SIFT)\n2Plotly Dash\n","date":"30 Jun, 2022","permalink":"/projects/photo_photo/","section":"Projects","summary":"Using machine learning algorithms to detect Photo of a Photo","title":"Photo of Photo"},{"content":"\rLaunch App\rIntroduction #The aim of this project is to provide an educational tool that enhances understanding of Polynomial Regression1, model complexity, and the trade-offs between model fit and over-fitting in data analysis and predictive modeling.\nThe final product is an interactive app built using R Shiny. This application will allow users to explore polynomial regression by adjusting the degree of the polynomial along with other inputs to observe real-time updatesto the regression line, residual plots and key statistical metrics.\nBackground #During my undergraduate studies, I was fascinated by the numerical methods used to find approximate solutions for problems where exact solutions are difficult to obtain. These methods form the backbone of many machine learning algorithms, such as numerical linear algebra2 for solving regression problems with large datasets, optimization algoithm like gradient descent3 for minimizing cost functions, and backpropagation4 for solving complex chained derivatives when training neural networks5. This fascination inpired me to create an interactive tool that demonstrates these principles in action.\nBuilding the App #The application is built using R Shiny, a powerful tool beloved by R enthusiasts and those interested in creating interactive dashboards using the wide range of statistical modeling packages native in R.\nR Shiny simplifies deployment to local environments with minimal effort, although mastering its UI syntax requires some learning, unlike tools such as Dash that supports syntax similar to HTML in Python.\nThe source code can be found here at GitHub.\nHow to use the App #User Inputs:\nInput expression for the function f(x) to generate sample data points for the application Adjust the range of input values for x in Value Range for x input box User can increase or decrease the Number of Points to be generated Set Seed for Noise RNG for generating the same set of random points Adjust the Variance Level for Noise in the data - higher variance makes the data noisier and appear more random Max Polynomial Degree Fitted controls the maximum degree of the polynomial used. Click the tiny Play button to visualize animated changes as higher polynomial degrees are added Plot X Axis Range to change the area of the plot to be viewed based on the ranges of the x values Tabs:\nPlot\nUser inputs and the main plot area for visualization as well as the regression summary details Residual Plots\nResidual plots of the model predictions vs actual values as higher degree polynomials is added Data\nAll raw input and model prediction values in a table Conclusion #Thank you for reading! If you like to learn more details about Polynomial Regression1 you can also check out this article I wrote on Medium Polynomial Regression„Ä∞Ô∏è and play with the app as you read it or leave a comment below (GitHub required).\nReferences #1\r\u003c?xml version=\"1.0\" encoding=\"iso-8859-1\"?\u003e\r\u003c!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"\u003e\rPolynomial Regression 2\r\u003c?xml version=\"1.0\" encoding=\"iso-8859-1\"?\u003e\r\u003c!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"\u003e\rNumerical Linear Algebra 3\r\u003c?xml version=\"1.0\" encoding=\"iso-8859-1\"?\u003e\r\u003c!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"\u003e\rGradient Descent 4\r\u003c?xml version=\"1.0\" encoding=\"iso-8859-1\"?\u003e\r\u003c!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"\u003e\rBackpropagation 5\r\u003c?xml version=\"1.0\" encoding=\"iso-8859-1\"?\u003e\r\u003c!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"\u003e\rNeural Networks\n","date":"06 Feb, 2021","permalink":"/projects/polyfit/","section":"Projects","summary":"Interactive R Shiny App to Visualize Polynomial Regression","title":"Polyfit„Ä∞Ô∏è"},{"content":"","date":null,"permalink":"/tags/predictive-modeling/","section":"Tags","summary":"","title":"Predictive Modeling"},{"content":"","date":null,"permalink":"/tags/r-shiny/","section":"Tags","summary":"","title":"R Shiny"},{"content":"\rA picture of me - Jun, 2024\rHi! ‰Ω†Â•Ω! üëã\nMy name is Steven Lio. I was born in Hong Kong, China and grew up in Macau, China. I moved to Canada in 2007 and currently living in Toronto, Ontario.\nI received my Master of Data Science from University of British Columbia (Canada) and my Bachelor of Science degree in Statistics from McMaster University (Canada).\nWith over 6 years of professional experience, I specialized in developing data-driven solutions and workflows to extract actionable insights that support strategic decision-making for cross-functional teams in Government, Telecom, Retail and Software industries. I possess a natural curiousity and a keen eye for detail when analyzing data, enabling me to find the optimal solutions for finding data-driven solutions and drive business decisions.\nProficient in Python and R, I excel in creating end-to-end machine learning workflows for data science projects. My expertise includes developing efficient data pipelines, conducting feature engineering, implementing machine learning models and building interactive visualization applications. Like this one here.\nI have practical experience tackling real-world challenges by applying machine learning algorithms for a variety of tasks. These include classification, clustering, statistical inference, regression modeling, time series modeling, all aimed at enhancing analytical insights and decision-making process. I have also developed advanced machine learning models such as implementing and training neural networks (CNN) for image classification, segmentation, computer vision tasks. My expertise extends to writing complex SQL queries for processing and aggregating large datasets, and designing robust data ETL processes.\nMy advanced data analytics have supported marketing strategy research in areas such as Predicting Customer Value, Customer Segmentation, Sentiment Analysis, Market Potential and Shares Estimation, Competitor Analysis, Optimizing Sales Channels.\nSomething else about me #On my free time, I enjoyed roaming in the nature and photography. I loves animals and I have a cat named \u0026ldquo;H«îH«î\u0026rdquo; (Tiger in Mandarin Chinese). I also play the piano and guitar. My favourites composers are Chopin and Beethoven.\nIf you are interested to learn more about me, feel free to message me on LinkedIn, or follow me on Instagram.\nFavourite quotes: #\u0026ldquo;MEOW~\u0026rdquo; - HuHu\n\u0026ldquo;All models are wrong, but some are useful\u0026rdquo; - George Box\n\u0026ldquo;We are the representatives of the cosmos; we are an example of what hydrogen atoms can do, given 15 billion years of cosmic evolution.\u0026rdquo; - Carl Sagan\nCheck out the projects I\u0026rsquo;ve previously worked on:\nLearn More\r","date":null,"permalink":"/about/","section":"","summary":"A picture of me - Jun, 2024\rHi!","title":"About me"},{"content":"","date":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"Technical Skills # Programming Languages: Python\r, R\r, SQL\rC#\r, VB.NET\r, .Net Development\rHtml\r, CSS\rMachine Learning Libraries: PyTorch\r, TensorFlow\r, scikit-learn\r, SciPy\r, pandas\r, numpy\r, OpenCV\r, Pillow\rData Visualization: Dash\r, Shiny\r, Plotly\r, Vega-Altair\r, matplotlib\r, ggplot\rTableau\r, PowerBI\rSoftware Development: Git\r, Github\r, Jira\r, Jenkins\r, Docker\r, PowerShell\r, bash\rOther tools: Microsoft SQL Server\r, Visual Studio\rArcGIS\r, QGIS\rSAS EG\r, MATLAB\r, MicroStrategy\rPower Automate Desktop\r, UiPath\r, Automation 360\r, BluePrism\rAnalytics topics: Customer Value Prediction\r, Customer Segmentation\r, Sentiment Analysis\rSeaonality Analysis\r, Market Potential and Shares Estimation\r, Competitor Analysis\rPre \u0026 Post Campaign Analysis\r, Optimizing Sales Channel\rProfessional Experience #\rData Scientist ¬∑ Blueprint Software System\nSep, 2022 ‚Äì Jun, 2024\nQuality Assurance Business Analyst ¬∑ Blueprint Software System\nApr, 2021 ‚Äì Aug, 2022\nData Scientist ¬∑ Bell Mobility\nJan, 2020 ‚Äì Dec, 2020\nMarket Insight Analyst ¬∑ Bell Mobility\nAug, 2017 ‚Äì Dec, 2019\nData QA Analyst ¬∑ Environment and Climate Change Canada\nMay, 2016 ‚Äì Apr, 2017\nCo-op / Internship #\rData QA Support ¬∑ Environment and Climate Change Canada\nMay, 2015 ‚Äì Dec, 2015\nAssistant Methodologist ¬∑ Statistics Canada\nJan, 2014 ‚Äì Aug, 2014\nProjects #Segmentation of Coral baby ¬∑ Personal Project\nJan, 2023 - Jun, 2023\nDeveloped an image segmentation model using a U-Net architecture with transfer learning from ResNet50 to identify coral babies in raw images of coral frags Photo of Photo ¬∑ Trusting Pixels Inc.\nMay, 2022 - Jun, 2022\nCollaborated on a team to develop a proof-of-concept machine learning model to detect recaptured images Built an interactive Dash application incorporating the best model, allowing users to annotate and identify false recaptured images Project Page Polyfit ¬∑ Personal Project\nFeb, 2021 - Feb, 2021\nInteractive R Shiny tool for visualizing curve fitting using polynomials Project Page, GitHub Launch App\rEducation #\rMasters of Data Science\nUniversity of British Columbia\nSep, 2021 - Aug, 2022\nHonors Bachelor of Science - Mathematics and Statistics Co-op\nMcMaster University\nSep, 2011 - Aug, 2016\nMisc. Information # Languages: English, Cantonese, Mandarin Download R√©sum√©\r","date":null,"permalink":"/resume/","section":"","summary":"Technical Skills # Programming Languages: Python\r, R\r, SQL\rC#\r, VB.","title":"R√©sum√©"}]